import os
import sys
import subprocess
import redis
import signal
import logging
from pathlib import Path

# ===================== æ ¸å¿ƒé…ç½®ï¼ˆé€‚é…æ ¹ç›®å½•ç»“æ„ï¼‰=====================
# 1. Redisé…ç½®ï¼ˆä»æ ¹ç›®å½•çš„config.pyå¯¼å…¥ï¼‰
sys.path.insert(0, str(Path(__file__).absolute().parent))  # æŠŠæ ¹ç›®å½•åŠ å…¥Pythonç¯å¢ƒ
from config import (
    REDIS_HOST,
    REDIS_PORT,
    REDIS_DB,
    REDIS_PARAMS,
)

REDIS_CONF = {
    "host": REDIS_HOST,
    "port": REDIS_PORT,
    "db": REDIS_DB,
    "password": REDIS_PARAMS['password'],
    "decode_responses": True
}

# 2. Scrapyé…ç½®ï¼ˆå®šä½åˆ°wangxiao_scrapyç›®å½•é‡Œçš„scrapy.cfgï¼‰
SCRAPY_SPIDER_NAME = "questions"
SCRAPY_PROJECT_DIR = Path(__file__).absolute().parent / "wangxiao_scrapy"  # æŒ‡å‘wangxiao_scrapyç›®å½•
REDIS_URL_QUEUE_KEY = "questions:url"
DEFAULT_START_URL = "https://ks.wangxiao.cn/"

# 3. æ—¥å¿—é…ç½®ï¼ˆæ—¥å¿—æ”¾åˆ°results/logsï¼Œå’Œæ ¹ç›®å½•çš„resultsåŒçº§ï¼‰
LOG_FILE = Path(__file__).absolute().parent / "results/logs/spider_runner.log"
os.makedirs(os.path.dirname(LOG_FILE), exist_ok=True)  # è‡ªåŠ¨åˆ›å»ºæ—¥å¿—ç›®å½•

# ===================== æ—¥å¿—åˆå§‹åŒ– =====================
logging.basicConfig(
    level=logging.INFO,
    format="%(asctime)s - %(levelname)s - %(message)s",
    handlers=[
        logging.FileHandler(LOG_FILE, encoding="utf-8"),
        logging.StreamHandler(sys.stdout)
    ]
)
logger = logging.getLogger(__name__)


# ===================== æ ¸å¿ƒåŠŸèƒ½å‡½æ•° =====================
def check_redis_connection():
    """æ£€æŸ¥Redisè¿æ¥"""
    try:
        r = redis.Redis(**REDIS_CONF)
        r.ping()
        logger.info("âœ… Redisè¿æ¥æˆåŠŸ")
        return r
    except Exception as e:
        logger.error(f"âŒ Redisè¿æ¥å¤±è´¥: {e}")
        sys.exit(1)


def check_and_init_redis_queue(redis_client):
    """æ£€æŸ¥å¹¶åˆå§‹åŒ–Redis URLé˜Ÿåˆ—"""
    try:
        queue_len = redis_client.llen(REDIS_URL_QUEUE_KEY)
        logger.info(f"ğŸ“Š Redis URLé˜Ÿåˆ—é•¿åº¦: {queue_len}")
        if queue_len == 0:
            logger.warning(f"âš ï¸ é˜Ÿåˆ—ç©ºï¼Œè‡ªåŠ¨æ·»åŠ åˆå§‹URL: {DEFAULT_START_URL}")
            redis_client.lpush(REDIS_URL_QUEUE_KEY, DEFAULT_START_URL)
            logger.info("âœ… åˆå§‹URLå·²å†™å…¥Redis")
        return queue_len
    except Exception as e:
        logger.error(f"âŒ æ“ä½œRedisé˜Ÿåˆ—å¤±è´¥: {e}")
        sys.exit(1)


def run_scrapy_spider():
    """å¯åŠ¨Scrapyçˆ¬è™«ï¼ˆé€‚é…æ ¹ç›®å½•ç»“æ„ï¼‰"""
    # åˆ‡æ¢åˆ°Scrapyé¡¹ç›®ç›®å½•ï¼ˆwangxiao_scrapyï¼Œå†…å«scrapy.cfgï¼‰
    os.chdir(SCRAPY_PROJECT_DIR)

    # æ„å»ºå¯åŠ¨å‘½ä»¤
    cmd = [
        sys.executable,  # å½“å‰Pythonè§£é‡Šå™¨
        "-m", "scrapy", "crawl", SCRAPY_SPIDER_NAME,
        "--logfile", str(Path(__file__).absolute().parent / "results/logs/scrapy_spider.log")
    ]

    logger.info(f"ğŸš€ å¯åŠ¨å‘½ä»¤: {' '.join(cmd)}")
    logger.info(f"ğŸ“Œ Scrapyé¡¹ç›®ç›®å½•: {SCRAPY_PROJECT_DIR}")
    logger.info(f"ğŸ“Œ è„šæœ¬æ‰€åœ¨æ ¹ç›®å½•: {Path(__file__).absolute().parent}")

    spider_process = None
    try:
        # å¯åŠ¨çˆ¬è™«ï¼ˆå®æ—¶è¾“å‡ºæ—¥å¿—ï¼‰
        spider_process = subprocess.Popen(
            cmd,
            stdout=subprocess.PIPE,
            stderr=subprocess.STDOUT,
            text=True,
            encoding="utf-8",
            bufsize=1  # è¡Œç¼“å†²ï¼Œå®æ—¶è¾“å‡º
        )

        # å®æ—¶æ‰“å°çˆ¬è™«æ—¥å¿—
        for line in iter(spider_process.stdout.readline, ''):
            if line:
                logger.info(f"[SPIDER] {line.strip()}")

        exit_code = spider_process.wait()
        if exit_code == 0:
            logger.info("âœ… çˆ¬è™«æ­£å¸¸ç»“æŸ")
        else:
            logger.error(f"âŒ çˆ¬è™«å¼‚å¸¸é€€å‡ºï¼Œé€€å‡ºç : {exit_code}")
        return exit_code

    except KeyboardInterrupt:
        logger.warning("âš ï¸ ç”¨æˆ·æ‰‹åŠ¨ä¸­æ–­ï¼Œåœæ­¢çˆ¬è™«...")
        if spider_process:
            spider_process.send_signal(signal.SIGTERM)
            spider_process.wait()
        logger.info("ğŸ›‘ çˆ¬è™«å·²åœæ­¢")
        sys.exit(0)
    except Exception as e:
        logger.error(f"âŒ å¯åŠ¨çˆ¬è™«å¤±è´¥: {e}")
        if spider_process:
            spider_process.kill()
        sys.exit(1)


def main():
    logger.info("=" * 50)
    logger.info("ğŸ¯ å¯åŠ¨Scrapy-Redisçˆ¬è™«ï¼ˆæ ¹ç›®å½•ç‰ˆï¼Œå’ŒresultsåŒçº§ï¼‰")
    logger.info("=" * 50)

    # 1. æ£€æŸ¥Redisè¿æ¥
    redis_client = check_redis_connection()
    # 2. åˆå§‹åŒ–Redisé˜Ÿåˆ—
    check_and_init_redis_queue(redis_client)
    # 3. å¯åŠ¨çˆ¬è™«
    exit_code = run_scrapy_spider()

    logger.info("=" * 50)
    logger.info(f"ğŸ è„šæœ¬æ‰§è¡Œå®Œæˆï¼Œé€€å‡ºç : {exit_code}")
    logger.info("=" * 50)
    sys.exit(exit_code)


if __name__ == "__main__":
    main()