import asyncio
import random
import time
import aiohttp
import aiofiles
import redis.asyncio as redis
import json
import re
import os
import atexit
from pathlib import Path
from typing import List, Dict, Optional
from urllib.parse import urlparse
from collections import defaultdict
import logging
from config import (
    # Redisé…ç½®
    REDIS_HOST,
    REDIS_PORT,
    REDIS_DB,
    REDIS_PARAMS,
)
import sys
# é…ç½®æ—¥å¿—
logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(levelname)s - %(message)s',
    handlers=[logging.StreamHandler()]
)
logger = logging.getLogger(__name__)


class FileWriteQueue:
    """åŸºäºæ–‡ä»¶è·¯å¾„çš„ä»»åŠ¡é˜Ÿåˆ—"""

    def __init__(self):
        self.queues = defaultdict(asyncio.Queue)
        self.processing = set()

    async def enqueue_write(self, file_path, write_func):
        """å°†å†™å…¥ä»»åŠ¡åŠ å…¥é˜Ÿåˆ—"""
        queue = self.queues[file_path]
        await queue.put(write_func)

        # å¦‚æœè¯¥æ–‡ä»¶æ²¡æœ‰æ­£åœ¨å¤„ç†çš„ä»»åŠ¡ï¼Œå¯åŠ¨å¤„ç†
        if file_path not in self.processing:
            self.processing.add(file_path)
            asyncio.create_task(self._process_queue(file_path))

    async def _process_queue(self, file_path):
        """å¤„ç†ç‰¹å®šæ–‡ä»¶çš„æ‰€æœ‰å†™å…¥ä»»åŠ¡"""
        queue = self.queues[file_path]

        while not queue.empty():
            write_func = await queue.get()
            try:
                await write_func()
            except Exception as e:
                print(f"å†™å…¥æ–‡ä»¶ {file_path} å¤±è´¥: {e}")
            finally:
                queue.task_done()

        self.processing.remove(file_path)

write_queue = FileWriteQueue()
class AsyncMDExporter:
    """å¼‚æ­¥ä¿å­˜åˆ°Markdownæ–‡ä»¶"""

    def __init__(self, redis_host=REDIS_HOST, redis_port=REDIS_PORT, redis_db=REDIS_DB):
        # Redisè¿æ¥å°†åœ¨å¼‚æ­¥ä¸Šä¸‹æ–‡ä¸­åˆå§‹åŒ–
        self.redis_host = redis_host
        self.redis_port = redis_port
        self.redis_db = redis_db
        self.redis_params = REDIS_PARAMS

        # Rediså®¢æˆ·ç«¯å®ä¾‹
        self.redis: Optional[redis.Redis] = None
        self.redis_key = 'questions:items'

        # ä¼šè¯ç®¡ç†
        self.session: Optional[aiohttp.ClientSession] = None

        # é™åˆ¶å¹¶å‘æ•° - å‡å°å¹¶å‘ä»¥é™ä½æ–‡ä»¶å¥æŸ„å‹åŠ›
        self.semaphore = asyncio.Semaphore(10)  # ä»30å‡å°åˆ°10
        self.file_semaphore = asyncio.Semaphore(20)  # ä¸“é—¨ç”¨äºæ–‡ä»¶æ“ä½œçš„ä¿¡å·é‡

        # æ·»åŠ æ‰¹å¤„ç†æ§åˆ¶
        self.batch_size = 50  # æ¯æ¬¡å¤„ç†çš„æ‰¹æ¬¡å¤§å°

        # ç»Ÿè®¡
        self.stats = {
            'total': 0,
            'success': 0,
            'failed': 0,
            'images_downloaded': 0,
            'images_failed': 0
        }

    async def init_redis(self):
        """åˆå§‹åŒ–å¼‚æ­¥Redisè¿æ¥"""
        try:
            self.redis = await redis.Redis(
                host=self.redis_host,
                port=self.redis_port,
                db=self.redis_db,
                password=self.redis_params.get('password'),
                decode_responses=True,
                socket_connect_timeout=5,
                socket_timeout=5
            )
            # æµ‹è¯•è¿æ¥
            await self.redis.ping()
            logger.info("âœ… Rediså¼‚æ­¥è¿æ¥æˆåŠŸ")
        except Exception as e:
            logger.error(f"âŒ Redisè¿æ¥å¤±è´¥: {e}")
            raise

    async def init_session(self):
        """åˆå§‹åŒ–aiohttpä¼šè¯"""
        timeout = aiohttp.ClientTimeout(total=30)
        self.session = aiohttp.ClientSession(timeout=timeout)

    async def close(self):
        """å…³é—­æ‰€æœ‰è¿æ¥"""
        if self.redis:
            await self.redis.close()
            logger.info("Redisè¿æ¥å·²å…³é—­")

        if self.session:
            await self.session.close()
            logger.info("HTTPä¼šè¯å·²å…³é—­")

    async def get_valid_data(self, limit: Optional[int] = None) -> List[Dict]:
        """ä»Redisè·å–æœ‰æ•ˆæ•°æ®ï¼ˆå¼‚æ­¥ç‰ˆæœ¬ï¼‰"""
        if not self.redis:
            await self.init_redis()

        logger.info("ğŸ“¥ ä»Redisè·å–æ•°æ®...")

        total = await self.redis.llen(self.redis_key)
        logger.info(f"ğŸ“Š Redisä¸­å…±æœ‰ {total} æ¡æ•°æ®")

        if limit:
            total = min(total, limit)

        valid_data = []
        for i in range(total):
            try:
                item_json = await self.redis.lindex(self.redis_key, i)
                if not item_json:
                    continue

                item = json.loads(item_json)

                # è¿‡æ»¤æ— æ•ˆæ•°æ®
                if not item.get('content') or not item.get('textAnalysis'):
                    continue

                if not item.get('path'):
                    continue

                valid_data.append(item)

            except Exception as e:
                logger.warning(f"ç¬¬{i}æ¡æ•°æ®è§£æå¤±è´¥: {e}")
                continue

        logger.info(f"âœ… è·å–åˆ° {len(valid_data)} æ¡æœ‰æ•ˆæ•°æ®")
        return valid_data

    def extract_img_urls(self, text: str) -> List[str]:
        """æå–æ–‡æœ¬ä¸­çš„å›¾ç‰‡URL"""
        if not text:
            return []

        # åŒ¹é…æ‰€æœ‰imgæ ‡ç­¾çš„srcå±æ€§
        pattern = r'src="([^"]+)"'
        urls = re.findall(pattern, text)

        # è¿‡æ»¤å¹¶è¿”å›
        return [url for url in urls if url.startswith('http')]

    async def download_image(self, img_url: str, save_dir: Path) -> Optional[str]:
        """å¼‚æ­¥ä¸‹è½½å•å¼ å›¾ç‰‡"""
        if not self.session:
            return None

        # ç”Ÿæˆæ–‡ä»¶å
        try:
            filename = img_url.split('/')[-1]
            # æ¸…ç†æ–‡ä»¶åï¼ˆç§»é™¤æŸ¥è¯¢å‚æ•°ç­‰ï¼‰
            filename = filename.split('?')[0]

            # ç¡®ä¿æ˜¯å›¾ç‰‡æ–‡ä»¶
            if not any(filename.lower().endswith(ext) for ext in ['.jpg', '.jpeg', '.png', '.gif', '.bmp', '.webp']):
                filename += '.jpg'  # é»˜è®¤åŠ .jpgæ‰©å±•å

            save_path = save_dir / filename

            async with self.semaphore:
                try:
                    async with self.session.get(img_url) as response:
                        if response.status == 200:
                            content = await response.read()
                            async with aiofiles.open(save_path, 'wb') as f:
                                await f.write(content)

                            self.stats['images_downloaded'] += 1
                            if self.stats['images_downloaded'] % 10 == 0:
                                logger.info(f"ğŸ“¸ å·²ä¸‹è½½ {self.stats['images_downloaded']} å¼ å›¾ç‰‡...")

                            return str(save_path.relative_to(save_dir.parent))
                        else:
                            logger.warning(f"å›¾ç‰‡ä¸‹è½½å¤±è´¥ {img_url}: çŠ¶æ€ç  {response.status}")
                except Exception as e:
                    logger.warning(f"å›¾ç‰‡ä¸‹è½½å¤±è´¥ {img_url}: {e}")

        except Exception as e:
            logger.warning(f"å¤„ç†å›¾ç‰‡URLå¤±è´¥ {img_url}: {e}")

        self.stats['images_failed'] += 1
        return None

    async def replace_img_urls(self, text: str, img_dir: Path) -> str:
        """æ›¿æ¢æ–‡æœ¬ä¸­çš„å›¾ç‰‡URLä¸ºæœ¬åœ°è·¯å¾„"""
        img_urls = self.extract_img_urls(text)

        if not img_urls:
            return text

        # ä¸‹è½½æ‰€æœ‰å›¾ç‰‡
        download_tasks = []
        for img_url in img_urls:
            task = self.download_image(img_url, img_dir)
            download_tasks.append((img_url, task))

        # ç­‰å¾…æ‰€æœ‰ä¸‹è½½å®Œæˆ
        results = {}
        for img_url, task in download_tasks:
            local_path = await task
            if local_path:
                results[img_url] = local_path

        # æ›¿æ¢URL
        if results:
            for img_url, local_path in results.items():
                # æ›¿æ¢srcå±æ€§
                text = text.replace(f'src="{img_url}"', f'src="./{local_path}"')
                # åŒæ—¶æ›¿æ¢æ²¡æœ‰å¼•å·çš„æƒ…å†µ
                text = text.replace(f'src={img_url}', f'src=./{local_path}')

        return text

    def process_answer(self, analysis: str) -> str:
        """å¤„ç†ç­”æ¡ˆï¼šå°†å¼€å¤´çš„æ•°å­—æˆ–å­—æ¯è½¬æ¢ä¸ºæ ‡å‡†æ ¼å¼"""
        if not analysis:
            return "", analysis

        # æå–å¼€å¤´çš„ç­”æ¡ˆï¼ˆå­—æ¯æˆ–æ•°å­—ï¼‰
        match = re.match(r'^([A-Z0-9]+)', analysis)
        if not match:
            return "", analysis

        answer = match.group(1)

        # å¦‚æœæ˜¯æ•°å­—ï¼Œè½¬æ¢ä¸ºæ­£ç¡®/é”™è¯¯
        if answer.isdigit():
            if answer == '1':
                display_answer = "âœ… æ­£ç¡®"
            elif answer == '0':
                display_answer = "âŒ é”™è¯¯"
            else:
                display_answer = f"ç­”æ¡ˆ: {answer}"
        else:
            # å­—æ¯ç­”æ¡ˆ
            if len(answer) == 1:
                display_answer = f"æ­£ç¡®ç­”æ¡ˆ: {answer}"
            else:
                display_answer = f"æ­£ç¡®ç­”æ¡ˆ: {', '.join(list(answer))}"

        # ä»è§£æä¸­ç§»é™¤ç­”æ¡ˆéƒ¨åˆ†
        remaining_analysis = analysis[len(answer):]
        # ç§»é™¤å¼€å¤´çš„<p>æ ‡ç­¾ï¼ˆå¦‚æœæœ‰ï¼‰
        if remaining_analysis.startswith('<p>'):
            remaining_analysis = remaining_analysis[3:]

        return display_answer, remaining_analysis

    def clean_html_for_markdown(self, html: str) -> str:
        """æ¸…ç†HTMLï¼Œè½¬æ¢ä¸ºMarkdownå‹å¥½æ ¼å¼"""
        if not html:
            return ""

        # ä¿ç•™imgæ ‡ç­¾
        html = html.replace('<p>', '').replace('</p>', '')

        # ä¿ç•™æ¢è¡Œ
        html = html.replace('<br>', '\n').replace('<br/>', '\n').replace('<br />', '\n')

        # æ¸…ç†å¤šä½™çš„ç©ºç™½
        html = re.sub(r'\s+', ' ', html).strip()

        return html

    def format_question_content(self, content: str) -> str:
        """æ ¼å¼åŒ–é¢˜ç›®å†…å®¹ï¼Œæ·»åŠ é«˜äº®æ•ˆæœ"""
        highlighted = f'{content}<p style="white-space: normal;">'
        return highlighted

    def format_options(self, options: List[str]) -> str:
        """æ ¼å¼åŒ–é€‰é¡¹ï¼Œæ·»åŠ é«˜äº®æ•ˆæœ"""
        if not options:
            return ""

        formatted_options = []
        for i, option in enumerate(options):
            option = option.strip()
            if not option:
                continue

            formatted = f"{option}"
            formatted_options.append(formatted)

        # æ¯ä¸ªé€‰é¡¹å•ç‹¬ä¸€è¡Œï¼Œç”¨ç©ºè¡Œåˆ†éš”
        return "<br>".join(formatted_options)

    def format_analysis(self, analysis: str) -> str:
        """æ ¼å¼åŒ–è§£æå†…å®¹"""
        if not analysis:
            return ""

        analysis = self.clean_html_for_markdown(analysis)
        return f"{analysis}"

    def create_markdown_header(self, path: List[str]) -> str:
        """åˆ›å»ºMarkdownæ–‡ä»¶å¤´éƒ¨ä¿¡æ¯"""
        if len(path) >= 3:
            # ä½¿ç”¨æœ€åä¸‰å±‚ä½œä¸ºæ ‡é¢˜
            title = " -> ".join(path[-3:])
        else:
            title = " -> ".join(path)

        # åˆ›å»ºå¸¦æ ·å¼çš„æ ‡é¢˜
        header = f"""# ğŸ“š {title}

> åˆ†ç±»: {' -> '.join(path)}

---

"""
        return header

    async def save_single_md(self, item: Dict, output_base: Path):
        """ä¿å­˜å•ä¸ªé¢˜ç›®ä¸ºMarkdownæ–‡ä»¶"""
        try:
            # 1. å‡†å¤‡è·¯å¾„ä¸”è¿‡æ»¤æ— æ•ˆ
            path = item.get('path', [])
            if len(path) < 3:
                logger.warning(f"è·¯å¾„å¤ªçŸ­: {path}")
                return False

            # æ–‡ä»¶åï¼šæœ€åä¸€å±‚
            filename = path[-1].replace('/', '_').replace('\\', '_')
            if len(filename) > 50:  # å¢åŠ æ–‡ä»¶åé•¿åº¦é™åˆ¶
                filename = filename[:50]
            filename = re.sub(r'[<>:"|?*]', '', filename) + '.md'

            # ä¿å­˜è·¯å¾„ï¼šé™¤æœ€åä¸€å±‚çš„æ‰€æœ‰å±‚
            save_dir = output_base
            for part in path[:-1]:
                safe_part = part.replace('/', '_').replace('\\', '_')
                safe_part = re.sub(r'[<>:"|?*]', '', safe_part)
                save_dir = save_dir / safe_part

            # å›¾ç‰‡æ–‡ä»¶å¤¹
            img_dir = save_dir / f"{filename.replace('.md', '_img')}"

            # åˆ›å»ºç›®å½•
            save_dir.mkdir(parents=True, exist_ok=True)
            img_dir.mkdir(parents=True, exist_ok=True)

            # 2. å¤„ç†æ•°æ®
            content = item.get('content', '')
            options = item.get('options', [])
            analysis = item.get('textAnalysis', '')

            # ä¸‹è½½å¹¶æ›¿æ¢å›¾ç‰‡
            content = await self.replace_img_urls(content, img_dir)
            analysis = await self.replace_img_urls(analysis, img_dir)

            # å¤„ç†ç­”æ¡ˆ
            answer, clean_analysis = self.process_answer(analysis)

            # æ ¼å¼åŒ–å„éƒ¨åˆ†å†…å®¹
            formatted_content = self.format_question_content(content)
            formatted_options = self.format_options(options)
            formatted_analysis = self.format_analysis(clean_analysis)

            # 3. å†™å…¥Markdownæ–‡ä»¶ - ä½¿ç”¨æ–‡ä»¶ä¿¡å·é‡æ§åˆ¶å¹¶å‘
            md_path = save_dir / filename

            async def actual_write():
                async with self.file_semaphore:  # æ§åˆ¶åŒæ—¶æ‰“å¼€çš„æ–‡ä»¶æ•°é‡
                    async with aiofiles.open(md_path, 'a+', encoding='utf-8', errors='replace') as f:
                        # ç¬¬ä¸€æ­¥ï¼šå°†æ–‡ä»¶æŒ‡é’ˆç§»åˆ°æ–‡ä»¶å¼€å¤´ï¼ˆè§£å†³a+é»˜è®¤æŒ‡é’ˆåœ¨æœ«å°¾çš„é—®é¢˜ï¼‰
                        await f.seek(0)
                        # ç¬¬äºŒæ­¥ï¼šå¼‚æ­¥è¯»å–æ–‡ä»¶å†…å®¹
                        file_content = await f.read()
                        # time.sleep(random.randint(1, 5))
                        # ç¬¬ä¸‰æ­¥ï¼šåˆ¤æ–­å†…å®¹æ˜¯å¦å­˜åœ¨ï¼Œä¸å­˜åœ¨åˆ™è¿½åŠ 
                        header = self.create_markdown_header(path)
                        if header not in file_content:
                            # å†™å…¥æ–‡ä»¶å¤´éƒ¨å’Œæ–‡ä»¶ç”Ÿæˆæ—¶é—´
                            await f.write(header)
                            await f.write(f"\n*é¢˜ç›®ä¿å­˜æ—¶é—´: {self.get_current_time()}*\n")
                            # æ·»åŠ åˆ†éš”çº¿å’Œæ—¶é—´æˆ³
                            await f.write("\n")
                            await f.write('---')

                        # æ£€æŸ¥å†…å®¹æ˜¯å¦å·²å­˜åœ¨
                        content_check = formatted_content[:100]  # åªæ£€æŸ¥å‰100ä¸ªå­—ç¬¦
                        if content_check not in file_content:
                            # å†™å…¥é¢˜ç›®éƒ¨åˆ†
                            await f.write('\n\n\n---\n')
                            await f.write(f'{formatted_content}')

                            # å†™å…¥é€‰é¡¹éƒ¨åˆ†
                            if formatted_options:
                                await f.write(f'<p>{formatted_options}</p><p style="white-space: normal;">')

                            # å†™å…¥ç­”æ¡ˆéƒ¨åˆ†
                            if answer:
                                await f.write(f'{answer},')

                            # å†™å…¥è§£æéƒ¨åˆ†
                            if formatted_analysis:
                                await f.write(f"{formatted_analysis}<br>")

            await write_queue.enqueue_write(md_path, actual_write)

            self.stats['success'] += 1
            if self.stats['success'] % 100 == 0:
                logger.info(f"âœ… å·²ä¿å­˜ {self.stats['success']} ä¸ªæ–‡ä»¶...")

            return True

        except Exception as e:
            logger.error(f"ä¿å­˜æ–‡ä»¶å¤±è´¥: {e}")
            self.stats['failed'] += 1
            return False

    def get_current_time(self):
        """è·å–å½“å‰æ—¶é—´"""
        from datetime import datetime
        return datetime.now().strftime("%Y-%m-%d %H:%M:%S")

    async def process_batch(self, data: List[Dict], output_base: Path):
        """æ‰¹é‡å¤„ç†æ•°æ® - åˆ†æ‰¹å¤„ç†é¿å…æ‰“å¼€å¤ªå¤šæ–‡ä»¶"""
        logger.info(f"ğŸš€ å¼€å§‹å¤„ç† {len(data)} æ¡æ•°æ®...")

        # åˆ†æ‰¹å¤„ç†
        for i in range(0, len(data), self.batch_size):
            batch = data[i:i + self.batch_size]
            logger.info(
                f"ğŸ“¦ å¤„ç†æ‰¹æ¬¡ {i // self.batch_size + 1}/{(len(data) - 1) // self.batch_size + 1} (å…± {len(batch)} æ¡)")

            # åˆ›å»ºä»»åŠ¡
            tasks = []
            for item in batch:
                task = self.save_single_md(item, output_base)
                tasks.append(task)

            # å¹¶å‘æ‰§è¡Œä½†ç­‰å¾…æ‰¹æ¬¡å®Œæˆ
            results = await asyncio.gather(*tasks, return_exceptions=True)

            # æ¯æ‰¹å¤„ç†å®Œåç¨ä½œä¼‘æ¯
            await asyncio.sleep(0.1)

        logger.info(f"ğŸ‰ æ‰¹é‡å¤„ç†å®Œæˆ!")

    async def run(self, limit: Optional[int] = None, output_dir: str = '../results/q_all'):
        """è¿è¡Œå®Œæ•´æµç¨‹"""
        logger.info("ğŸš€ å¼€å§‹å¼‚æ­¥å¯¼å‡ºåˆ°Markdown")

        try:
            # åˆå§‹åŒ–è¿æ¥
            await self.init_redis()
            await self.init_session()

            # è·å–æ•°æ®
            data = await self.get_valid_data(limit)
            if not data:
                logger.warning("âš ï¸ æ²¡æœ‰è·å–åˆ°æœ‰æ•ˆæ•°æ®")
                return

            self.stats['total'] = len(data)

            # åˆ›å»ºè¾“å‡ºç›®å½•
            output_base = Path(output_dir)
            output_base.mkdir(parents=True, exist_ok=True)

            # å¤„ç†æ•°æ®
            await self.process_batch(data, output_base)

            # æ‰“å°ç»Ÿè®¡
            logger.info("=" * 50)
            logger.info("ğŸ“Š æœ€ç»ˆç»Ÿè®¡:")
            logger.info(f"  å¤„ç†æ€»æ•°: {self.stats['total']}")
            logger.info(f"  æˆåŠŸä¿å­˜: {self.stats['success']}")
            logger.info(f"  ä¿å­˜å¤±è´¥: {self.stats['failed']}")
            logger.info(f"  å›¾ç‰‡ä¸‹è½½: {self.stats['images_downloaded']}")
            logger.info(f"  å›¾ç‰‡å¤±è´¥: {self.stats['images_failed']}")
            logger.info("=" * 50)

        except Exception as e:
            logger.error(f"âŒ è¿è¡Œå¤±è´¥: {e}")
        finally:
            # å…³é—­æ‰€æœ‰è¿æ¥
            await self.close()


# @atexit.register
def remove_empty_folders_pathlib(path):
    path_obj = Path(path)
    for folder in sorted(path_obj.rglob('*'), key=lambda p: len(p.parts), reverse=True):
        if folder.is_dir() and not any(folder.iterdir()):
            folder.rmdir()
            # print(f"å·²åˆ é™¤ç©ºæ–‡ä»¶å¤¹: {folder}")

    print("å­˜å‚¨ç»“æŸ")


# å¿«é€Ÿæµ‹è¯•å‡½æ•°
async def test_single_item():
    """æµ‹è¯•å•ä¸ªé¢˜ç›®å¤„ç†"""
    exporter = AsyncMDExporter()

    # æµ‹è¯•æ•°æ®
    test_item = {
        'path': ['ç¨åŠ¡å¸ˆ', 'ç¨æ³•äºŒ', 'ç¬¬å…­ç« è½¦èˆ¹ç¨', 'ç¬¬äºŒèŠ‚å¾ç¨èŒƒå›´ã€çº³ç¨äººå’Œé€‚ç”¨ç¨é¢', 'ä¸‰ã€ç¨ç›®ã€ç¨é¢'],
        'content': '<p>æœ‰å…³èˆ¹ç¨çš„è®¡ç¨ä¾æ®ï¼Œä¸‹åˆ—è¡¨è¿°æ­£ç¡®çš„æœ‰ï¼ˆï¼‰ã€‚</p>',
        'options': ['Aã€è½¦è¾†æ•´å¤‡è´¨é‡å°¾æ•°åœ¨0.5å¨ä»¥ä¸‹çš„ä¸è®¡ç®—è½¦èˆ¹ç¨', 'Bã€æŒ‚è½¦æŒ‰è½½è´§æ±½è½¦è´§è½¦ç¨é¢çš„50ï¼…è®¡å¾è½¦èˆ¹ç¨',
                    'Cã€å·²ç¼´çº³è½¦èˆ¹ç¨çš„è½¦èˆ¹åœ¨åŒä¸€çº³ç¨å¹´åº¦å†…åŠç†è½¬è®©è¿‡æˆ·çš„ï¼Œéœ€å¦è¡Œçº³ç¨', 'Dã€éæœºåŠ¨é©³èˆ¹ï¼Œå…å¾è½¦èˆ¹ç¨'],
        'textAnalysis': 'B<p>å¦‚å›¾æ‰€ç¤ºï¼š<img title="1.png" src="http://img.wangxiao.cn/bjupload/2020-10-29/53f7a0c0-57de-45d4-aef7-e8137f5309e4.png" /><br /></p><p>ï¼ˆçŸ¥è¯†ç‚¹ï¼šç¨ç›®ã€ç¨é¢ï¼‰</p><p>ï¼ˆé¢˜åº“ç»´æŠ¤è€å¸ˆï¼šzhxï¼‰</p>'}

    # åˆå§‹åŒ–è¿æ¥
    await exporter.init_redis()
    await exporter.init_session()

    # æµ‹è¯•ä¿å­˜
    output_base = Path('../results/test_q')
    result = await exporter.save_single_md(test_item, output_base)

    # é¢„è§ˆç”Ÿæˆçš„å†…å®¹
    if result:
        # æ„å»ºæ­£ç¡®çš„æ–‡ä»¶è·¯å¾„
        safe_filename = test_item['path'][-1].replace('/', '_').replace('\\', '_')
        if len(safe_filename) > 50:
            safe_filename = safe_filename[:50]
        safe_filename = re.sub(r'[<>:"|?*]', '', safe_filename) + '.md'

        # æ„å»ºç›®å½•è·¯å¾„
        save_dir = output_base
        for part in test_item['path'][:-1]:
            safe_part = part.replace('/', '_').replace('\\', '_')
            safe_part = re.sub(r'[<>:"|?*]', '', safe_part)
            save_dir = save_dir / safe_part

        md_path = save_dir / safe_filename

        if md_path.exists():
            print("\n" + "=" * 50)
            print("ğŸ“„ ç”Ÿæˆçš„Markdownå†…å®¹é¢„è§ˆ:")
            print("=" * 50)
            async with aiofiles.open(md_path, 'r', encoding='utf-8', errors='replace') as f:
                content = await f.read()
                print(content[:500] + "..." if len(content) > 500 else content)
            print("=" * 50)

    print(f"\næµ‹è¯•ç»“æœ: {'æˆåŠŸ' if result else 'å¤±è´¥'}")

    await exporter.close()


# ä¸»å‡½æ•°
async def main():


    # è§£æå‚æ•°
    limit = None
    output_dir = '../results/q_all'
    atexit.register(remove_empty_folders_pathlib, output_dir)
    if len(sys.argv) > 1:
        try:
            limit = int(sys.argv[1])
            print(f"å°†å¤„ç†å‰ {limit} æ¡æ•°æ®")
        except ValueError:
            print(f"æ— æ•ˆçš„é™åˆ¶å‚æ•°: {sys.argv[1]}")

    if len(sys.argv) > 2:
        output_dir = sys.argv[2]

    print(f"è¾“å‡ºç›®å½•: {output_dir}")
    print("=" * 50)

    # åˆ›å»ºå¯¼å‡ºå™¨
    exporter = AsyncMDExporter()

    # è¿è¡Œå¯¼å‡º
    await exporter.run(limit=limit, output_dir=output_dir)

    print("\nğŸ‰ å¯¼å‡ºå®Œæˆï¼")


if __name__ == '__main__':
    # è¿è¡Œæµ‹è¯•å‡½æ•°
    # print("ğŸ§ª å…ˆè¿è¡Œæµ‹è¯•...")
    # asyncio.run(test_single_item())
    #
    # print("\n" + "=" * 50)

    print("ğŸš€ å¼€å§‹ä¸»ç¨‹åº...")
    print("=" * 50)

    # è¯¢é—®æ˜¯å¦ç»§ç»­
    response = input("\næ˜¯å¦æŠŠredisæ•°æ®åº“çš„æ•°æ®ä¿å­˜ä¸ºç›¸åº”çš„Markdownæ–‡ä»¶(y/n): ").strip().lower()
    if response == 'y':
        # è¿è¡Œä¸»å‡½æ•°
        asyncio.run(main())
    else:
        print("ç¨‹åºé€€å‡º")